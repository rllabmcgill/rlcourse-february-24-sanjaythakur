{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjay/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#WAIT TIME\n",
    "wait_time = 0.05\n",
    "\n",
    "#Defining colors for highlighting important aspects\n",
    "GREEN = lambda x: '\\x1b[32m{}\\x1b[0m'.format(x)\n",
    "BLUE = lambda x: '\\x1b[34m{}\\x1b[0m'.format(x)\n",
    "RED = lambda x: '\\x1b[31m{}\\x1b[0m'.format(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forbidden states of the Dyna Maze\n",
    "FORBIDDEN_STATES = ['11', '20', '29', '41', '07', '16', '25']\n",
    "\n",
    "#All possible actions defined\n",
    "ACTION_UP = 'UP'\n",
    "ACTION_DOWN = 'DOWN'\n",
    "ACTION_LEFT = 'LEFT'\n",
    "ACTION_RIGHT = 'RIGHT'\n",
    "        \n",
    "#All actions\n",
    "all_actions = [ACTION_UP, ACTION_RIGHT, ACTION_DOWN, ACTION_LEFT]\n",
    "\n",
    "#All states in Dyna-Maze\n",
    "all_states = ['00', '01', '02', '03', '04', '05', '06', '07', '08',\n",
    "            '09', '10', '11', '12', '13', '14', '15', '16', '17', \n",
    "            '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
    "            '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
    "            '36', '37', '38', '39', '40', '41', '42', '43', '44',\n",
    "            '45', '46', '47', '48', '49', '50', '51', '52', '53']\n",
    "\n",
    "#All transitions in Dyna-Maze\n",
    "all_transitions =  {\n",
    "    '00': {ACTION_UP : '00', ACTION_RIGHT : '01', ACTION_DOWN: '09', ACTION_LEFT: '00'},\n",
    "    '01': {ACTION_UP : '01', ACTION_RIGHT : '02', ACTION_DOWN: '10', ACTION_LEFT: '00'},\n",
    "    '02': {ACTION_UP : '02', ACTION_RIGHT : '03', ACTION_DOWN: '02', ACTION_LEFT: '01'},\n",
    "    '03': {ACTION_UP : '03', ACTION_RIGHT : '04', ACTION_DOWN: '12', ACTION_LEFT: '02'},\n",
    "    '04': {ACTION_UP : '04', ACTION_RIGHT : '05', ACTION_DOWN: '13', ACTION_LEFT: '03'},\n",
    "    '05': {ACTION_UP : '05', ACTION_RIGHT : '06', ACTION_DOWN: '14', ACTION_LEFT: '04'},\n",
    "    '06': {ACTION_UP : '06', ACTION_RIGHT : '06', ACTION_DOWN: '15', ACTION_LEFT: '05'},\n",
    "    '07': {ACTION_UP : '07', ACTION_RIGHT : '07', ACTION_DOWN: '07', ACTION_LEFT: '07'},\n",
    "    '08': {ACTION_UP : '08', ACTION_RIGHT : '08', ACTION_DOWN: '17', ACTION_LEFT: '08'},\n",
    "    '09': {ACTION_UP : '00', ACTION_RIGHT : '10', ACTION_DOWN: '18', ACTION_LEFT: '09'},\n",
    "    '10': {ACTION_UP : '01', ACTION_RIGHT : '10', ACTION_DOWN: '19', ACTION_LEFT: '09'},\n",
    "    '11': {ACTION_UP : '11', ACTION_RIGHT : '11', ACTION_DOWN: '11', ACTION_LEFT: '11'},\n",
    "    '12': {ACTION_UP : '03', ACTION_RIGHT : '13', ACTION_DOWN: '21', ACTION_LEFT: '12'},\n",
    "    '13': {ACTION_UP : '04', ACTION_RIGHT : '14', ACTION_DOWN: '22', ACTION_LEFT: '12'},\n",
    "    '14': {ACTION_UP : '05', ACTION_RIGHT : '15', ACTION_DOWN: '23', ACTION_LEFT: '13'},\n",
    "    '15': {ACTION_UP : '06', ACTION_RIGHT : '15', ACTION_DOWN: '24', ACTION_LEFT: '14'},\n",
    "    '16': {ACTION_UP : '16', ACTION_RIGHT : '16', ACTION_DOWN: '16', ACTION_LEFT: '16'},\n",
    "    '17': {ACTION_UP : '08', ACTION_RIGHT : '17', ACTION_DOWN: '26', ACTION_LEFT: '17'},\n",
    "    '18': {ACTION_UP : '09', ACTION_RIGHT : '19', ACTION_DOWN: '27', ACTION_LEFT: '18'},\n",
    "    '19': {ACTION_UP : '10', ACTION_RIGHT : '19', ACTION_DOWN: '28', ACTION_LEFT: '18'},\n",
    "    '20': {ACTION_UP : '20', ACTION_RIGHT : '20', ACTION_DOWN: '20', ACTION_LEFT: '20'},\n",
    "    '21': {ACTION_UP : '12', ACTION_RIGHT : '22', ACTION_DOWN: '30', ACTION_LEFT: '21'},\n",
    "    '22': {ACTION_UP : '13', ACTION_RIGHT : '23', ACTION_DOWN: '31', ACTION_LEFT: '21'},\n",
    "    '23': {ACTION_UP : '14', ACTION_RIGHT : '24', ACTION_DOWN: '32', ACTION_LEFT: '22'},\n",
    "    '24': {ACTION_UP : '15', ACTION_RIGHT : '24', ACTION_DOWN: '33', ACTION_LEFT: '23'},\n",
    "    '25': {ACTION_UP : '25', ACTION_RIGHT : '25', ACTION_DOWN: '25', ACTION_LEFT: '25'},\n",
    "    '26': {ACTION_UP : '17', ACTION_RIGHT : '26', ACTION_DOWN: '35', ACTION_LEFT: '26'},\n",
    "    '27': {ACTION_UP : '18', ACTION_RIGHT : '28', ACTION_DOWN: '36', ACTION_LEFT: '27'},\n",
    "    '28': {ACTION_UP : '19', ACTION_RIGHT : '28', ACTION_DOWN: '37', ACTION_LEFT: '27'},\n",
    "    '29': {ACTION_UP : '29', ACTION_RIGHT : '29', ACTION_DOWN: '29', ACTION_LEFT: '29'},\n",
    "    '30': {ACTION_UP : '21', ACTION_RIGHT : '31', ACTION_DOWN: '39', ACTION_LEFT: '30'},\n",
    "    '31': {ACTION_UP : '22', ACTION_RIGHT : '32', ACTION_DOWN: '40', ACTION_LEFT: '30'},\n",
    "    '32': {ACTION_UP : '23', ACTION_RIGHT : '33', ACTION_DOWN: '32', ACTION_LEFT: '31'},\n",
    "    '33': {ACTION_UP : '24', ACTION_RIGHT : '34', ACTION_DOWN: '42', ACTION_LEFT: '32'},\n",
    "    '34': {ACTION_UP : '34', ACTION_RIGHT : '35', ACTION_DOWN: '43', ACTION_LEFT: '33'},\n",
    "    '35': {ACTION_UP : '26', ACTION_RIGHT : '35', ACTION_DOWN: '44', ACTION_LEFT: '34'},\n",
    "    '36': {ACTION_UP : '27', ACTION_RIGHT : '37', ACTION_DOWN: '45', ACTION_LEFT: '36'},\n",
    "    '37': {ACTION_UP : '28', ACTION_RIGHT : '38', ACTION_DOWN: '46', ACTION_LEFT: '36'},\n",
    "    '38': {ACTION_UP : '38', ACTION_RIGHT : '39', ACTION_DOWN: '47', ACTION_LEFT: '37'},\n",
    "    '39': {ACTION_UP : '30', ACTION_RIGHT : '40', ACTION_DOWN: '48', ACTION_LEFT: '38'},\n",
    "    '40': {ACTION_UP : '31', ACTION_RIGHT : '40', ACTION_DOWN: '49', ACTION_LEFT: '39'},\n",
    "    '41': {ACTION_UP : '41', ACTION_RIGHT : '41', ACTION_DOWN: '41', ACTION_LEFT: '41'},\n",
    "    '42': {ACTION_UP : '33', ACTION_RIGHT : '43', ACTION_DOWN: '51', ACTION_LEFT: '42'},\n",
    "    '43': {ACTION_UP : '34', ACTION_RIGHT : '44', ACTION_DOWN: '52', ACTION_LEFT: '42'},\n",
    "    '44': {ACTION_UP : '35', ACTION_RIGHT : '44', ACTION_DOWN: '53', ACTION_LEFT: '43'},\n",
    "    '45': {ACTION_UP : '36', ACTION_RIGHT : '46', ACTION_DOWN: '45', ACTION_LEFT: '45'},\n",
    "    '46': {ACTION_UP : '37', ACTION_RIGHT : '47', ACTION_DOWN: '46', ACTION_LEFT: '45'},\n",
    "    '47': {ACTION_UP : '38', ACTION_RIGHT : '48', ACTION_DOWN: '47', ACTION_LEFT: '46'},\n",
    "    '48': {ACTION_UP : '39', ACTION_RIGHT : '49', ACTION_DOWN: '48', ACTION_LEFT: '47'},\n",
    "    '49': {ACTION_UP : '40', ACTION_RIGHT : '50', ACTION_DOWN: '49', ACTION_LEFT: '48'},\n",
    "    '50': {ACTION_UP : '50', ACTION_RIGHT : '51', ACTION_DOWN: '50', ACTION_LEFT: '49'},\n",
    "    '51': {ACTION_UP : '42', ACTION_RIGHT : '52', ACTION_DOWN: '51', ACTION_LEFT: '50'},\n",
    "    '52': {ACTION_UP : '43', ACTION_RIGHT : '53', ACTION_DOWN: '52', ACTION_LEFT: '51'},\n",
    "    '53': {ACTION_UP : '44', ACTION_RIGHT : '53', ACTION_DOWN: '53', ACTION_LEFT: '52'},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All functions to set the parameters and datastructures of the environment are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def defineStateActionImmediateRewards(END_STATE):\n",
    "    immediate_state_rewards = {}\n",
    "    for state in all_states:\n",
    "        action_rewards = {}\n",
    "        if state ==  END_STATE:\n",
    "            for action in all_actions:\n",
    "                action_rewards[action] = 1\n",
    "        else:\n",
    "            for action in all_actions:\n",
    "                \n",
    "                if all_transitions[state][action] == END_STATE:\n",
    "                    action_rewards[action] = 1\n",
    "                else:\n",
    "                    action_rewards[action] = 0\n",
    "        \n",
    "        immediate_state_rewards[state] = action_rewards\n",
    "    return immediate_state_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initializeStateActionValuePairs():        \n",
    "    state_action_value_pairs = {}\n",
    "    for state in all_states:\n",
    "        action_rewards = {}\n",
    "        for action in all_actions:\n",
    "            action_rewards[action] = 1\n",
    "        state_action_value_pairs[state] = action_rewards\n",
    "        \n",
    "    return state_action_value_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We initialize our policy. We initialize our state action values with all optimistic values so that we don't get stuck at any deadlocks.\n",
    "def initializeGreedyPolicy():\n",
    "    greedy_policy = {}\n",
    "    for state in all_states:\n",
    "        greedy_policy[state] = ACTION_RIGHT\n",
    "    return greedy_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initializeModelStateActionBag():\n",
    "    state_action_bag = {}\n",
    "    for state in all_states:\n",
    "        action_map = {}\n",
    "        for action in all_actions:\n",
    "            action_map[action] = ()\n",
    "        state_action_bag[state] = action_map\n",
    "    return state_action_bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other helper functions needed are defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updatePolicy(state_action_value_pairs, greedy_policy):\n",
    "    for state, action_values in state_action_value_pairs.items():\n",
    "        highest_valued_action = ACTION_UP\n",
    "        highest_value = action_values[ACTION_UP]\n",
    "        if highest_value < action_values[ACTION_RIGHT]:\n",
    "            highest_valued_action = ACTION_RIGHT\n",
    "            highest_value = action_values[ACTION_RIGHT]\n",
    "        if highest_value < action_values[ACTION_DOWN]:\n",
    "            highest_valued_action = ACTION_DOWN\n",
    "            highest_value = action_values[ACTION_DOWN]\n",
    "        if highest_value < action_values[ACTION_LEFT]:\n",
    "            highest_valued_action = ACTION_LEFT\n",
    "            highest_value = action_values[ACTION_LEFT]\n",
    "            \n",
    "        greedy_policy[state] = highest_valued_action\n",
    "\n",
    "def chooseActionStochastically():\n",
    "    random_throw = random.uniform(0, 1)\n",
    "    if random_throw < 0.25:\n",
    "        return ACTION_UP\n",
    "    elif random_throw < 0.5:\n",
    "        return ACTION_RIGHT\n",
    "    elif random_throw < 0.75:\n",
    "        return ACTION_DOWN\n",
    "    else:\n",
    "        return ACTION_LEFT\n",
    "    \n",
    "def takeAction(immediate_state_rewards, state, action):\n",
    "    reward = immediate_state_rewards[state][action]\n",
    "    next_state = all_transitions[state][action]\n",
    "    return next_state, reward\n",
    "\n",
    "def printPolicy(greedy_policy):\n",
    "    print(\"Latest Policy\", end = '')\n",
    "    for state in all_states:\n",
    "        if (int(state) % 9) == 0:\n",
    "            print(\"\\n\")\n",
    "        print(state, \"::\", greedy_policy[state],\"\\t\", end = '')\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "def printStateActionValuePairs(state_action_value_pairs):\n",
    "    print(\" \\t\", ACTION_UP, \"\\t\", ACTION_RIGHT, \"\\t\", ACTION_DOWN, \"\\t\", ACTION_LEFT)\n",
    "    for state in all_states:\n",
    "        print(state, \"\\t\", \"%.2f\" % state_action_value_pairs[state][ACTION_UP], \"\\t\", \"%.2f\" % state_action_value_pairs[state][ACTION_RIGHT], \"\\t\", \"%.2f\" % state_action_value_pairs[state][ACTION_DOWN], \"\\t\", \"%.2f\" % state_action_value_pairs[state][ACTION_LEFT],)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "def printDynaMaze(states_in_episode = []):\n",
    "    for state in all_states:\n",
    "        if (int(state) % 9) == 0:\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        if state in states_in_episode:\n",
    "            state = state.replace(state, GREEN(state))\n",
    "            \n",
    "        if state in FORBIDDEN_STATES:\n",
    "            state = state.replace(state, RED(state))\n",
    "        \n",
    "        print(state, \"\\t\", end = '')\n",
    "        \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DynaAgent():\n",
    "    def __init__(self, GAMMA = 0.95, ALPHA = 0.1, EPSILON = 1, TOTAL_EPISODES_TO_CONSIDER = 50, MAXIMUM_EPISODE_LENGTH = 1000, NUMBER_PLANNING_STEPS = 50, START_STATE = '18', END_STATE = '08', PLAN = True):\n",
    "        #Discount-factor\n",
    "        self.GAMMA = GAMMA\n",
    "        #ALPHA or step-size\n",
    "        self.ALPHA = ALPHA\n",
    "        #Defining the EPSILON which would ensure regular exploration. Our EPSILON will decrease linearly with each iteration of a episode and will eventually fade away to 0 .\n",
    "        self.EPSILON = EPSILON\n",
    "        #Number of episodes to consider\n",
    "        self.TOTAL_EPISODES_TO_CONSIDER = TOTAL_EPISODES_TO_CONSIDER\n",
    "        #Maximum allowed episode length\n",
    "        self.MAXIMUM_EPISODE_LENGTH = MAXIMUM_EPISODE_LENGTH\n",
    "        #Number of planning steps\n",
    "        self.NUMBER_PLANNING_STEPS = NUMBER_PLANNING_STEPS\n",
    "        #Start State\n",
    "        self.START_STATE = START_STATE\n",
    "        #End State\n",
    "        self.END_STATE = END_STATE\n",
    "        #Should incorporate planning in decision-making or not\n",
    "        self.PLAN = PLAN   \n",
    "        \n",
    "    #Parameters to mimic the environment. Remember that these parameters won't be known to us, not at least before we start moving our agent.\n",
    "    def setAllDataStructures(self):\n",
    "        self.immediate_state_rewards = defineStateActionImmediateRewards(self.END_STATE)\n",
    "        self.state_action_value_pairs = initializeStateActionValuePairs()\n",
    "        self.greedy_policy = initializeGreedyPolicy()\n",
    "        self.state_action_bag = initializeModelStateActionBag()\n",
    "     \n",
    "    # This function runs the agent which plans and learns simultaneously how to reach the goal state.\n",
    "    def runAgent(self):\n",
    "        all_observed_state_action_pairs = set()\n",
    "        all_episodes_length = []\n",
    "        all_episodes = []\n",
    "        for episode_iterator in range(self.TOTAL_EPISODES_TO_CONSIDER):\n",
    "            current_episode = [self.START_STATE]\n",
    "            self.EPSILON = (1/((0.2 * episode_iterator) + 1))\n",
    "            current_state = self.START_STATE\n",
    "            current_episode_length = 0\n",
    "            while(current_state != self.END_STATE and current_episode_length < self.MAXIMUM_EPISODE_LENGTH):\n",
    "                current_episode_length += 1\n",
    "                random_throw = random.uniform(0, 1)\n",
    "                if random_throw < self.EPSILON:\n",
    "                    current_action = chooseActionStochastically()\n",
    "                else:\n",
    "                    current_action = self.greedy_policy[current_state]\n",
    "                next_state, reward = takeAction(self.immediate_state_rewards, current_state, current_action)\n",
    "                self.state_action_value_pairs[current_state][current_action] = self.state_action_value_pairs[current_state][current_action] + (self.ALPHA * (reward + (self.GAMMA * self.state_action_value_pairs[next_state][self.greedy_policy[next_state]]) - self.state_action_value_pairs[current_state][current_action]))\n",
    "                all_observed_state_action_pairs.add((current_state, current_action))\n",
    "                self.state_action_bag[current_state][current_action] = (reward, next_state)\n",
    "                if self.PLAN == True:\n",
    "                    for planning_iterator in range(self.NUMBER_PLANNING_STEPS):\n",
    "                        random_picker = int(random.uniform(0, len(all_observed_state_action_pairs)))\n",
    "                        state_action_pair = list(all_observed_state_action_pairs)[random_picker]\n",
    "                        _state = state_action_pair[0]\n",
    "                        _action = state_action_pair[1]\n",
    "                        _reward, _next_state = self.state_action_bag[_state][_action]\n",
    "                        self.state_action_value_pairs[_state][_action] = self.state_action_value_pairs[_state][_action] + (self.ALPHA * (_reward + (self.GAMMA * self.state_action_value_pairs[_next_state][self.greedy_policy[_next_state]]) - self.state_action_value_pairs[_state][_action]))\n",
    "                    current_state = next_state\n",
    "                    current_episode.append(current_state)\n",
    "                    updatePolicy(self.state_action_value_pairs, self.greedy_policy)\n",
    "            all_episodes.append(current_episode)\n",
    "            all_episodes_length.append((current_episode_length + 1)) \n",
    "        return all_episodes, all_episodes_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agent_with_planning = DynaAgent()\n",
    "agent_with_planning.setAllDataStructures()\n",
    "all_episodes_from_planning, all_episodes_length_from_planning = agent_with_planning.runAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent_without_planning = DynaAgent(PLAN=False)\n",
    "agent_without_planning.setAllDataStructures()\n",
    "all_episodes_without_planning, all_episodes_length_without_planning = agent_without_planning.runAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nos.system(\\'clear\\')\\nfor episode_number in range(len(all_episodes)):\\n    episode = all_episodes[episode_number]\\n    for step_number in range(len(episode)):\\n        print(\"Episode number\", str(episode_number))\\n        printDynaMaze(episode[0:step_number])\\n        time.sleep(wait_time)\\n        os.system(\\'clear\\')\\n    time.sleep(4 * wait_time)\\n    \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Uncomment these lines to see demonstration, along with generating the python copy of this from 'File->Download As' and running it on the terminal \n",
    "\n",
    "'''\n",
    "os.system('clear')\n",
    "for episode_number in range(len(all_episodes)):\n",
    "    episode = all_episodes[episode_number]\n",
    "    for step_number in range(len(episode)):\n",
    "        print(\"Episode number\", str(episode_number))\n",
    "        printDynaMaze(episode[0:step_number])\n",
    "        time.sleep(wait_time)\n",
    "        os.system('clear')\n",
    "    time.sleep(4 * wait_time)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f53956b4f60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7f8D5jmoqobNaYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5397dd84a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_number = [x for x in range(len(all_episodes_from_planning))]\n",
    "plot(episode_number, all_episodes_length_from_planning, linewidth=2)\n",
    "plot(episode_number, all_episodes_length_without_planning, linewidth=2)\n",
    "grid(1)\n",
    "ylabel('Steps per episode')\n",
    "xlabel('Episodes -> ')\n",
    "legend(['With Planning', 'Without planning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
